data "aws_ami" "fck_nat" {
  most_recent = true
  owners      = ["568608671756"]


}
data "aws_ami" "ubuntu" {
  most_recent = true
  owners      = ["099720109477"] 

  filter {
    name   = "name"
    values = ["ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*"]
  }
}

data "aws_ami" "amazon_linux2" {
  most_recent = true
  owners      = ["137112412989"] 

  filter {
    name   = "name"
    values = ["amzn2-ami-hvm-*-x86_64-gp2"]
  }
}
resource "aws_security_group" "nat_appliance" {
  name   = "${var.project_name}-nat-appliance-sg"
  vpc_id = aws_vpc.main.id

  ingress {
    protocol    = "-1"
    from_port   = 0
    to_port     = 0
    cidr_blocks = ["0.0.0.0/0"]
  }
ingress {
    protocol    = "udp"
    from_port   = 6081
    to_port     = 6081
    cidr_blocks = ["0.0.0.0/0"]
  }
  ingress {
    protocol    = "tcp"
    from_port   = 22
    to_port     = 22
    cidr_blocks = ["0.0.0.0/0"]
  }
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  tags = {
    Name = "${var.project_name}-nat-appliance-sg"
  }
}
resource "aws_security_group" "ssh" {
  name   = "${var.project_name}-ssh-sg"
  vpc_id = aws_vpc.main.id
  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  tags = {
    Name = "${var.project_name}-ssh-sg"
  }
}
resource "aws_instance" "jump_box" {
  ami                    = data.aws_ami.amazon_linux2.id
  instance_type          = "t3.micro"
  subnet_id              = aws_subnet.public_d.id
    key_name               = aws_key_pair.ec2_key.key_name

  vpc_security_group_ids = [aws_security_group.ssh.id]
  tags = {
    Name = "${var.project_name}-ssh-instance"
  }
}

# FILE: ./compute.tf

resource "aws_launch_template" "nat_appliance" {
  name_prefix   = "${var.project_name}-nat-just-nat-ec2"
  image_id      = data.aws_ami.amazon_linux2.id
  instance_type = "t3.micro"
  key_name      = aws_key_pair.ec2_key.key_name
  iam_instance_profile {
    name = aws_iam_instance_profile.nat_profile.name
  }
  network_interfaces {
    security_groups             = [aws_security_group.nat_appliance.id]
    associate_public_ip_address = true
  }

  tag_specifications {
    resource_type = "instance"
    tags = {
      Name = "${var.project_name}-nat-appliance"
    }
  }
  user_data =  base64encode(<<-EOF
  #!/bin/bash
  set -e -x
  
  yum update -y
  yum install -y awscli iptables-services

  INSTANCE_ID=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)
  REGION=$(curl -s http://169.254.169.254/latest/meta-data/placement/region)
  aws ec2 modify-instance-attribute \
    --instance-id $INSTANCE_ID \
    --no-source-dest-check \
    --region $REGION

  echo "net.ipv4.ip_forward = 1" >> /etc/sysctl.conf
  sysctl -p

  modprobe geneve
  ip link add geneve0 type geneve id 0 remote 0.0.0.0 dstport 6081
  ip link set geneve0 up

  PRIMARY_INTERFACE=$(ip -o -4 route show to default | awk '{print $5}')
  iptables -t nat -A POSTROUTING -o $PRIMARY_INTERFACE -j MASQUERADE
  iptables -A FORWARD -i geneve0 -j ACCEPT
  iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT

  service iptables save
  systemctl enable iptables
  systemctl start iptables
EOF
  )

}
resource "aws_autoscaling_group" "nat_appliance" {
  name                = "${var.project_name}-nat-asg"
  desired_capacity    = 3
  min_size            = 1
  max_size            = 4
  vpc_zone_identifier = [aws_subnet.public_a.id, aws_subnet.public_b.id]
  target_group_arns   = [aws_lb_target_group.main.arn]
  
  
  
  
  launch_template {
    id      = aws_launch_template.nat_appliance.id
    version = "$Latest"
  }
}

resource "aws_security_group" "workload" {
  name   = "${var.project_name}-workload-sg"
  vpc_id = aws_vpc.main.id
  egress {
    from_port   = 0
    to_port     = 0
    protocol    = "-1"
    cidr_blocks = ["0.0.0.0/0"]
  }
  ingress {
    from_port   = 22
    to_port     = 22
    protocol    = "tcp"
    cidr_blocks = ["0.0.0.0/0"]
  }
  tags = { Name = "${var.project_name}-workload-sg" }
}

resource "aws_instance" "workload" {
  ami                    = data.aws_ami.amazon_linux2.id
  instance_type          = "t3.micro"
  subnet_id              = aws_subnet.private.id
  key_name               = aws_key_pair.ec2_key.key_name
  vpc_security_group_ids = [aws_security_group.workload.id]
  tags = {
    Name = "${var.project_name}-workload-instance"
  }
}resource "aws_iam_role" "nat_role" {
  name = "${var.project_name}-nat-role"

  assume_role_policy = jsonencode({
    Version = "2012-10-17",
    Statement = [
      {
        Effect = "Allow",
        Principal = { Service = "ec2.amazonaws.com" },
        Action   = "sts:AssumeRole"
      }
    ]
  })
}

resource "aws_iam_role_policy" "nat_policy" {
  name = "${var.project_name}-nat-policy"
  role = aws_iam_role.nat_role.id

  policy = jsonencode({
    Version = "2012-10-17",
    Statement = [
      {
        Effect   = "Allow",
        Action   = "ec2:ModifyInstanceAttribute",
        Resource = "*"
      }
    ]
  })
}

resource "aws_iam_instance_profile" "nat_profile" {
  name = "${var.project_name}-nat-profile"
  role = aws_iam_role.nat_role.name
}
resource "aws_lb" "main" {
  name               = "${var.project_name}-gwlb"
  load_balancer_type = "gateway"
  subnets            = [aws_subnet.public_a.id,aws_subnet.public_b.id]
  enable_deletion_protection = false
  enable_cross_zone_load_balancing = true
  tags = {
    Name = "${var.project_name}-gwlb"
  }
}
resource "aws_lb_listener" "main" {
  load_balancer_arn = aws_lb.main.arn

  default_action {
    type             = "forward"
    target_group_arn = aws_lb_target_group.main.arn
  }
}
resource "aws_lb_target_group" "main" {
  name        = "${var.project_name}-tg"
  port        = 6081
  protocol    = "GENEVE"
  vpc_id      = aws_vpc.main.id
  health_check {
    protocol = "TCP"
    port     = "22"
  }
}
resource "aws_vpc_endpoint_service" "main" {
  acceptance_required        = false
  gateway_load_balancer_arns = [aws_lb.main.arn]

  tags = {
    Name = "${var.project_name}-gwlb-service"
  }
}


resource "aws_vpc_endpoint" "main" {
  vpc_id            = aws_vpc.main.id
  service_name      = aws_vpc_endpoint_service.main.service_name
  vpc_endpoint_type = "GatewayLoadBalancer"
  subnet_ids        = [aws_subnet.endpoint_a.id]
  tags = {
    Name = ""
  }
}terraform {
  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

provider "aws" {
  region = var.region
}

data "aws_availability_zones" "available" {
  state = "available"
}# ############################################################
# # CloudWatch Log Group
# ############################################################
# resource "aws_cloudwatch_log_group" "vpc_flow_logs_group" {
#   name              = "/vpc/gwlb-nat-flow-logs-${var.project_name}"
#   retention_in_days = 7
# }

# ############################################################
# # IAM Role for VPC Flow Logs
# ############################################################
# resource "aws_iam_role" "vpc_flow_logs_role" {
#   name = "vpc-flow-logs-role-${var.project_name}"

#   assume_role_policy = jsonencode({
#     Version = "2012-10-17",
#     Statement = [
#       {
#         Effect    = "Allow",
#         Principal = { Service = "vpc-flow-logs.amazonaws.com" },
#         Action    = "sts:AssumeRole"
#       }
#     ]
#   })
# }

# resource "aws_iam_policy" "vpc_flow_logs_policy" {
#   name = "vpc-flow-logs-policy-${var.project_name}"

#   policy = jsonencode({
#     Version = "2012-10-17",
#     Statement = [
#       {
#         Action = [
#           "logs:CreateLogGroup",
#           "logs:CreateLogStream",
#           "logs:PutLogEvents",
#           "logs:DescribeLogGroups",
#           "logs:DescribeLogStreams"
#         ],
#         Effect   = "Allow",
#         Resource = "*"
#       }
#     ]
#   })
# }

# resource "aws_iam_role_policy_attachment" "vpc_flow_logs_attachment" {
#   role       = aws_iam_role.vpc_flow_logs_role.name
#   policy_arn = aws_iam_policy.vpc_flow_logs_policy.arn
# }

# ############################################################
# # Workload ENI Flow Log
# ############################################################
# resource "aws_flow_log" "workload_eni_flow_log" {
#   iam_role_arn    = aws_iam_role.vpc_flow_logs_role.arn
#   log_destination = aws_cloudwatch_log_group.vpc_flow_logs_group.arn
#   traffic_type    = "ALL"
#   eni_id          = aws_instance.workload.primary_network_interface_id

#   log_format = "$${version} $${action} $${log-status} $${interface-id} $${srcaddr} $${dstaddr} $${srcport} $${dstport} $${protocol} $${pkt-srcaddr} $${pkt-dstaddr}"
# }

# ############################################################
# # Data Source: NAT Appliance Instances
# ############################################################
# data "aws_instances" "nat_appliance_instances" {
#   instance_tags        = { Name = "${var.project_name}-nat-appliance" }
#   instance_state_names = ["running"]

#   depends_on = [aws_autoscaling_group.nat_appliance]
# }

# ############################################################
# # Data Source: Each NAT Instance
# ############################################################
# data "aws_instance" "nat_appliance_instance" {
#   for_each = toset(data.aws_instances.nat_appliance_instances.ids)

#   instance_id = data.aws_instances.nat_appliance_instances.ids[count.index]

#   depends_on = [data.aws_instances.nat_appliance_instances]
# }

# ############################################################
# # NAT ENI Flow Logs
# ############################################################
# resource "aws_flow_log" "nat_eni_flow_logs" {
#   for_each = toset(data.aws_instances.nat_appliance_instances.ids)


#   iam_role_arn    = aws_iam_role.vpc_flow_logs_role.arn
#   log_destination = aws_cloudwatch_log_group.vpc_flow_logs_group.arn
#   traffic_type    = "ALL"
#   eni_id          = data.aws_instance.nat_appliance_instance[count.index].primary_network_interface_id

#   depends_on = [data.aws_instances.nat_appliance_instances]
# }
resource "aws_vpc" "main" {
  cidr_block           = "10.20.0.0/16"
  enable_dns_support   = true
  enable_dns_hostnames = true
  tags = {
    Name = "${var.project_name}-vpc"
  }
}

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id
  tags = {
    Name = "${var.project_name}-igw"
  }
}

resource "aws_subnet" "private" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(aws_vpc.main.cidr_block, 8, 0)
  availability_zone = data.aws_availability_zones.available.names[0]
  tags = {
    Name = "${var.project_name}-private-subnet"
  }
}

resource "aws_subnet" "public_a" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(aws_vpc.main.cidr_block, 8, 1)
  availability_zone       = data.aws_availability_zones.available.names[0]
  map_public_ip_on_launch = true
  tags = {
    Name = "${var.project_name}-public-subnet-a"
  }
}

resource "aws_subnet" "public_b" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(aws_vpc.main.cidr_block, 8, 2)
  availability_zone       = data.aws_availability_zones.available.names[1]
  map_public_ip_on_launch = true
  tags = {
    Name = "${var.project_name}-public-subnet-b"
  }
}

resource "aws_subnet" "public_d" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = cidrsubnet(aws_vpc.main.cidr_block, 8, 3)
  availability_zone       = data.aws_availability_zones.available.names[1]
  map_public_ip_on_launch = true
  tags = {
    Name = "${var.project_name}-public-subnet-d"
  }
}

resource "aws_subnet" "endpoint_a" {
  vpc_id            = aws_vpc.main.id
  cidr_block        = cidrsubnet(aws_vpc.main.cidr_block, 8, 4)
  availability_zone = data.aws_availability_zones.available.names[0]
  tags = {
    Name = "${var.project_name}-endpoint-subnet-a"
  }
}

resource "aws_route_table" "public_nat" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }

  route {
    cidr_block      = aws_subnet.private.cidr_block
    vpc_endpoint_id = aws_vpc_endpoint.main.id
  }

  tags = { Name = "${var.project_name}-public-nat-rt" }
}

resource "aws_route_table" "private" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block      = "0.0.0.0/0"
    vpc_endpoint_id = aws_vpc_endpoint.main.id
  }

  tags = { Name = "${var.project_name}-private-rt" }
}

resource "aws_route_table" "endpoint" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }

  tags = { Name = "${var.project_name}-endpoint-rt" }
}

resource "aws_route_table" "public_jumbox" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }

  tags = { Name = "${var.project_name}-public-jumpbox-rt" }
}

resource "aws_route_table_association" "private" {
  subnet_id      = aws_subnet.private.id
  route_table_id = aws_route_table.private.id
}

resource "aws_route_table_association" "public_a" {
  subnet_id      = aws_subnet.public_a.id
  route_table_id = aws_route_table.public_nat.id
}

resource "aws_route_table_association" "public_b" {
  subnet_id      = aws_subnet.public_b.id
  route_table_id = aws_route_table.public_nat.id
}

resource "aws_route_table_association" "endpoint_a" {
  subnet_id      = aws_subnet.endpoint_a.id
  route_table_id = aws_route_table.endpoint.id
}

resource "aws_route_table_association" "public_d" {
  subnet_id      = aws_subnet.public_d.id
  route_table_id = aws_route_table.public_jumbox.id
}resource "local_file" "jump_box_connection_command" {
  filename = "scripts/connect_to_jumpbox.txt"
  content  = "ssh -i \"${aws_key_pair.ec2_key.key_name}.pem\" ec2-user@${aws_instance.jump_box.public_ip}"
}

resource "local_file" "workload_connection_command" {
  filename = "scripts/connect_to_workload_via_tunnel.txt"
  content  = "ssh -i \"${aws_key_pair.ec2_key.key_name}.pem\" -o ProxyCommand=\"ssh -W %h:%p -i '${aws_key_pair.ec2_key.key_name}.pem' ec2-user@${aws_instance.jump_box.public_ip}\" ec2-user@${aws_instance.workload.private_ip}"
}

output "jump_box_ssh_command" {
  description = "Command to connect to the Jump Box."
  value       = "ssh -i \"${aws_key_pair.ec2_key.key_name}.pem\" ec2-user@${aws_instance.jump_box.public_ip}"
}

output "workload_ssh_command" {
  description = "Command to connect to the Workload instance via the Jump Box tunnel."
  value       = "ssh -i \"${aws_key_pair.ec2_key.key_name}.pem\" -o ProxyCommand=\"ssh -W %h:%p -i '${aws_key_pair.ec2_key.key_name}.pem' ec2-user@${aws_instance.jump_box.public_ip}\" ec2-user@${aws_instance.workload.private_ip}"
}

# data "aws_network_interface" "gwlbe_eni" {
#   for_each = toset(aws_vpc_endpoint.main.network_interface_ids)
#   id       = each.key
# }

# # Output the private IPs of the Gateway Load Balancer Endpoint
# output "gateway_load_balancer_endpoint_ips" {
#   description = "The private IP addresses of the Gateway Load Balancer VPC Endpoint network interfaces."
#   value       = [for ni in data.aws_network_interface.gwlbe_eni : ni.private_ip]
# }resource "tls_private_key" "ssh_key" {
  algorithm = "RSA"
  rsa_bits  = 4096
}

resource "aws_key_pair" "ec2_key" {
  key_name   = "ec2-ssh-key"
  public_key = tls_private_key.ssh_key.public_key_openssh
}
resource "local_file" "ssh_private_key" {
  filename = "${path.module}/ec2-ssh-key.pem"
  content  = tls_private_key.ssh_key.private_key_pem
  file_permission = "0400"
}variable "region" {
  description = "The AWS region to deploy resources in."
  type        = string
  default     = "eu-west-1"
}

variable "project_name" {
  description = "A prefix used for naming all resources."
  type        = string
  default     = "custom-nat-gwlb"
}

